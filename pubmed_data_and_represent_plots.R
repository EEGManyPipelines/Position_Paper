rm(list=ls())

## load required packages

#install.packages("XML")
#install.packages("tidyverse")
#install.packages("rentrez")
#install.packages('maps')

library(tidyverse)
library(rentrez)
library(XML)
library(ggplot2)
library(maps)
library(countrycode)
library(dplyr)

# load the pupmed ids
# this txt file can be generated by either 
# a) calling the api in the browser and downloading the ids as a .txt file
# or
# b) utilizing the rentrez package to search and fetch the ids
# this process has to be repeated mulitple times due to the api maximally showing 10000 results

esearch_one <- entrez_search(db="pubmed", term="EEG",mindate=2017, maxdate=2022, retmax=10000, retstart=0)
esearch_two <- entrez_search(db="pubmed", term="EEG",mindate=2017, maxdate=2022, retmax=10000, retstart=10000)
esearch_three <- entrez_search(db="pubmed", term="EEG",mindate=2017, maxdate=2022, retmax=10000, retstart=20000)
esearch_four <- entrez_search(db="pubmed", term="EEG",mindate=2017, maxdate=2022, retmax=10000, retstart=30000)
esearch_five <- entrez_search(db="pubmed", term="EEG",mindate=2017, maxdate=2022, retmax=10000, retstart=40000)

# the ids are extracted and appended together
eeg_paps <- append(esearch_one$ids, c(esearch_two$ids, esearch_three$ids, esearch_four$ids,esearch_five$ids))
eeg_paps_sub = data.frame(eeg_paps[])

# iteratively extract the info from the pupmed id by
# accessing the pupmed api. This is probably not best practice as the api is called 
# extremly often but it works create an empty dataframe to house the affiliations and the ids

df_affiliations <- data.frame(matrix(ncol=20, nrow=0))#ncol is the max number of countries within a single publication
title =c()
name <- c()

for (i in 1:nrow(eeg_paps_sub)){ 
  
  studies<-entrez_fetch(db="pubmed", id=eeg_paps_sub[i,1], rettype="xml", parsed=TRUE)#pubmed api
  
  if (!is_empty(xpathSApply(studies, "//ArticleTitle", xmlValue))){
    title[i]<-xpathSApply(studies, "//ArticleTitle", xmlValue) #get title of the paper
  }
  
  if (!is_empty(xpathSApply(studies, "//LastName", xmlValue))){
    name[i]<-paste(xpathSApply(studies, c("//LastName","//ForeName"), xmlValue), collapse=", ") #get author names
  }
  
  affiliations<-xpathSApply(studies, "//Affiliation", xmlValue) # get affiliations
  
  if (!is_empty(affiliations)){
    
    #Removing punctuation
    rm_pun <- gsub("[[:punct:]\n]","",affiliations)
    
    # Split data at word boundaries
    country_split <- strsplit(rm_pun, " ")
    
    # Match with country in world.countries (world package)
    CountryList_raw <- lapply(country_split, function(x)x[which(toupper(x) %in% toupper(world.cities$country.etc))])
    countries = unique(data.frame(x=unlist(data.frame(do.call(rbind, CountryList_raw))))) # take only one mention of each country
    
    # add countries of a single publication to df_affiliations where rows are publications and columns are countries
    if (!is_empty(as.list(countries))){
      col = nrow(countries)
      df_affiliations[nrow(df_affiliations)+1,1:col] = do.call(rbind, as.list(countries))
    }
    
  }
  
}

setwd("***")
save(df_affiliations, file = "***")
save(name, file = "***")
save(title, file = "***")

all_one=data.frame(x=unlist(df_affiliations))
data=as.data.frame(sort(table(all_one$x), decreasing = T))

# some countries are duplicated because they are capitalized, join those
duplic = data[duplicated(tolower(data$Var1)),]

while (nrow(duplic)>0){
  
  dup_row = data[which(tolower(data$Var1) == tolower(duplic$Var1[1])), ]
  data$Freq[as.numeric(row.names(dup_row)[1])] = sum(dup_row$Freq)#add the number of occurances
  rows=which(tolower(data$Var1) == tolower(duplic$Var1[1]))
  data <- data[-c(rows[2]),] #remove the second appearance
  duplic = data[duplicated(tolower(data$Var1)),]
  
}
save(data, file = "***")

### GROUP COUNTRIES INTO CONTINENTS ###

data$continent <- countrycode(sourcevar = data[, "Var1"],
                              origin = "country.name",
                              destination = "continent")
data$continent[is.na(data$continent)]<-"Europe" # Kosovo was not classified. Add it to Europe
continents <- unique(data$continent)

#count percentage of occurances
country_all<- sum(data$Freq)
country_count = data.frame(continents)
country_count$count <- integer(5)
country_count$count[1] <- sum(data$Freq[data$continent=='Americas'])/country_all*100
country_count$count[2] <- sum(data$Freq[data$continent=='Asia'])/country_all*100
country_count$count[3] <- sum(data$Freq[data$continent=='Europe'])/country_all*100
country_count$count[4] <- sum(data$Freq[data$continent=='Oceania'])/country_all*100
country_count$count[5] <- sum(data$Freq[data$continent=='Africa'])/country_all*100

## PLOT CONTINENTS ##

country_count %>%
  arrange(count) %>%
  mutate(continents = factor(continents, levels=continents)) %>%
  ggplot(aes(x=continents, y=count)) + 
  geom_bar(stat="identity", fill="#4682B4", alpha=.6, width=.4) +
  coord_flip() +
  labs( x ="", y = "Number of papers (%)") +theme_classic()+ theme(text = element_text(size = 25))

## Plot continents for EEGManyPipelines sample ##

emp <- read.csv("***/demographic_cleaned_07092022.csv")
emp$cotinent <- countrycode(sourcevar = emp$country, origin = "country.name",destination = "continent")
emp$cotinent[is.na(emp$cotinent)]<-"Europe"  # Kosovo was not classified. Add it to Europe

#count percentage of occurances

emp_count = data.frame(continents)
emp_count$count <- integer(5)
emp_all<-sum(c(sum(emp$cotinent=='Americas'),sum(emp$cotinent=='Asia'),sum(emp$cotinent=='Europe'), sum(emp$cotinent=='Oceania'),
               sum(emp$cotinent=='Africa')))
emp_count$count[1] <- sum(emp$cotinent=='Americas')/emp_all*100
emp_count$count[2] <- sum(emp$cotinent=='Asia')/emp_all*100
emp_count$count[3] <- sum(emp$cotinent=='Europe')/emp_all*100
emp_count$count[4] <- sum(emp$cotinent=='Oceania')/emp_all*100
emp_count$count[5] <- sum(emp$cotinent=='Africa')/emp_all*100

emp_count %>%
  arrange(count) %>%
  mutate(continents = factor(continents, levels=continents)) %>%
  ggplot(aes(x=continents, y=count)) + 
  geom_bar(stat="identity", fill="#5F9EA0", alpha=.6, width=.4) +
  coord_flip() +
  labs( x ="", y = "Number of teams(%)") +theme_classic()+ theme(text = element_text(size = 25))


## Combine both plots ##
all_count = rbind(country_count,emp_count)
all_count$fill <-integer(10)
all_count$fill[1:5]<- "pubmed"
all_count$fill[6:10]<- "emp"

#Dodge position two bars next to each other
all_count %>%
  ggplot(aes(continents, count, fill = fill)) + 
  geom_bar(stat="identity",position = "dodge", alpha=.6, width=0.8) +ylim(0,100)+ 
  geom_text(aes(label=paste(round(count, digits=1), '%')), size = 7,vjust = 0.4, hjust=-0.2,
            position=position_dodge(width=0.9))+
  coord_flip() + scale_fill_manual("legend", values = c("#5F9EA0","#4682B4"), name="Based on:",labels=c("EMP sample","PubMed publications"))+
  labs( x ="", y = "Percentage") +theme_classic()+ theme(text = element_text(size = 25))+ 
  theme(legend.position="top")

#a single bar split into two
all_count %>%
  mutate(name = fct_relevel(continents,"Africa", "Americas", "Asia", "Europe", "Oceania")) %>%
  ggplot(aes(continents, count, fill = factor(fill) )) +geom_bar(stat="identity")+ylim(0,150)+
  geom_text(aes(y= c(8,8,19,3,5,29,29,75,20,200), label=paste(round(count, digits=0), '%')), vjust=0.5, hjust=0.2, color="dimgray", size=5)+ coord_flip() + 
  scale_fill_brewer(palette="Blues", labels = c("PubMed publications","Analysts"),breaks=c("pubmed","emp"))+
  labs( x ="", y = "Percentage")+ theme_classic() +theme(legend.position="top", axis.text.x=element_blank(),legend.title = element_blank() ,
                                                         text = element_text(size = 25, color='dimgray')) 
write.csv(all_count, '***/percent_countries_pubmed_emp_figure.csv')

